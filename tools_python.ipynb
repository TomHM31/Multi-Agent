{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "# read local .env file\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_anthropic.output_parsers import ToolsOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_model_id = 'claude-3-opus-20240229'\n",
    "sonnet_model_id = 'claude-3-sonnet-20240229'\n",
    "haiku_model_id = 'claude-3-haiku-20240307'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class PythonREPL(BaseModel):\n",
    "    \"\"\"A Python REPL that can be used to executed Python code\"\"\"\n",
    "    code: str = Field(description=\"Code block to be executed in a Python REPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosclay/Documents/VSCode/langgraph-multi-agent/venv/lib/python3.10/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n",
      "/Users/rosclay/Documents/VSCode/langgraph-multi-agent/venv/lib/python3.10/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `bind_tools` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatAnthropic(model=opus_model_id) #,default_headers={\"anthropic-beta\": \"tools-2024-04-04\"}\n",
    "structured_llm = llm.with_structured_output(PythonREPL, include_raw=True)\n",
    "\n",
    "llm_with_tools = llm.bind_tools([PythonREPL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunnableBinding' object has no attribute 'with_structured_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm_with_both \u001b[38;5;241m=\u001b[39m \u001b[43mllm_with_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m(PythonREPL, include_raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RunnableBinding' object has no attribute 'with_structured_output'"
     ]
    }
   ],
   "source": [
    "llm_with_both = llm_with_tools.with_structured_output(PythonREPL, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'first': {'name': None,\n",
       "  'steps': {'raw': {'name': None,\n",
       "    'bound': {'_type': 'anthropic-chat'},\n",
       "    'kwargs': {'tools': [{'name': 'PythonREPL',\n",
       "       'description': 'A Python REPL that can be used to executed Python code',\n",
       "       'input_schema': {'type': 'object',\n",
       "        'properties': {'code': {'description': 'Code block to be executed in a Python REPL',\n",
       "          'type': 'string'}},\n",
       "        'required': ['code']}}]},\n",
       "    'config': {},\n",
       "    'config_factories': [],\n",
       "    'custom_input_type': None,\n",
       "    'custom_output_type': None}}},\n",
       " 'middle': [],\n",
       " 'last': {'name': None,\n",
       "  'runnable': {'name': None,\n",
       "   'mapper': {'name': None,\n",
       "    'steps': {'parsed': {'name': None,\n",
       "      'first': RunnableLambda(itemgetter('raw')),\n",
       "      'middle': [],\n",
       "      'last': {'name': None,\n",
       "       'first_tool_only': True,\n",
       "       'args_only': False,\n",
       "       'pydantic_schemas': [__main__.PythonREPL]}},\n",
       "     'parsing_error': RunnableLambda(...)}}},\n",
       "  'fallbacks': [{'name': None,\n",
       "    'mapper': {'name': None,\n",
       "     'steps': {'parsed': RunnableLambda(lambda _: None)}}}],\n",
       "  'exceptions_to_handle': (Exception,),\n",
       "  'exception_key': 'parsing_error'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'bound': {'_type': 'anthropic-chat'},\n",
       " 'kwargs': {'tools': [{'name': 'PythonREPL',\n",
       "    'description': 'A Python REPL that can be used to executed Python code',\n",
       "    'input_schema': {'type': 'object',\n",
       "     'properties': {'code': {'description': 'Code block to be executed in a Python REPL',\n",
       "       'type': 'string'}},\n",
       "     'required': ['code']}}]},\n",
       " 'config': {},\n",
       " 'config_factories': [],\n",
       " 'custom_input_type': None,\n",
       " 'custom_output_type': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke('write a python function to square a number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = llm_with_tools | ToolsOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke('write a python function to square a number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tools.invoke('hi how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = '''1. Get all pitch data from 2020-08-01 to 2020-08-07:\n",
    "all_pitches = statcast('2020-08-01', '2020-08-07')\n",
    "\n",
    "2. Filter for just curveballs:\n",
    "all_curves = all_pitches[all_pitches['pitch_type'] == 'CU']\n",
    "\n",
    "3. Create a feature vector for each pitcher's curveballs:\n",
    "pitcher_curves = all_curves.groupby('pitcher')\n",
    "pitcher_features = pitcher_curves[['release_speed', 'release_spin', 'pfx_x', 'pfx_z']].mean().reset_index()\n",
    "\n",
    "4. Get Max Scherzer's player ID:\n",
    "from pybaseball import playerid_lookup\n",
    "scherzer_id = playerid_lookup('scherzer', 'max')['key_mlbam'][0]\n",
    "\n",
    "5. Get Scherzer's feature vector:\n",
    "scherzer_features = pitcher_features[pitcher_features['pitcher'] == scherzer_id]\n",
    "\n",
    "6. Import scikit-learn and create a knn model:\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=4)\n",
    "knn.fit(pitcher_features[['release_speed', 'release_spin', 'pfx_x', 'pfx_z']])\n",
    "\n",
    "7. Find the 3 pitchers closest to Scherzer:\n",
    "distances, indices = knn.kneighbors(scherzer_features[['release_speed', 'release_spin', 'pfx_x', 'pfx_z']])\n",
    "closest_indices = indices[0][1:4]\n",
    "similar_pitchers = pitcher_features.iloc[closest_indices]\n",
    "print(similar_pitchers[['pitcher']])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(f'Execute the next step of this plan:\\n\\n{plan}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0]['args']['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "#from langchain_community.chat_models import BedrockChat\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# read local .env file\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# define language model\n",
    "model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "#model_id = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "#llm = BedrockChat(model_id=model_id, model_kwargs={'temperature': 0})\n",
    "\n",
    "opus_model_id = 'claude-3-opus-20240229'\n",
    "sonnet_model_id = 'claude-3-sonnet-20240229'\n",
    "haiku_model_id = 'claude-3-haiku-20240307'\n",
    "\n",
    "llm = ChatAnthropic(model=opus_model_id, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke('what day comes after tuesday?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
